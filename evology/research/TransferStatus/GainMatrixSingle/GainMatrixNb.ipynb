{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "mode = 'static'\n",
    "\n",
    "if mode == 'learning':\n",
    "\n",
    "    standard_coord = pd.read_csv(\"/Users/aymericvie/Documents/GitHub/evology/evology/research/TransferStatus/GainMatrixSingle/data/neutral_combined/static_standard.csv\")\n",
    "    NT_bump_coord = pd.read_csv(\"/Users/aymericvie/Documents/GitHub/evology/evology/research/TransferStatus/GainMatrixSingle/data/neutral_combined/static_NT_bump.csv\")\n",
    "    VI_bump_coord = pd.read_csv(\"/Users/aymericvie/Documents/GitHub/evology/evology/research/TransferStatus/GainMatrixSingle/data/neutral_combined/static_VI_bump.csv\")\n",
    "    TF_bump_coord = pd.read_csv(\"/Users/aymericvie/Documents/GitHub/evology/evology/research/TransferStatus/GainMatrixSingle/data/neutral_combined/static_TF_bump.csv\")\n",
    "\n",
    "if mode == 'static':\n",
    "    standard_coord = pd.read_csv(\"/Users/aymericvie/Documents/GitHub/evology/evology/research/TransferStatus/GainMatrixSingle/data/neutral_static/static_standard.csv\")\n",
    "    NT_bump_coord = pd.read_csv(\"/Users/aymericvie/Documents/GitHub/evology/evology/research/TransferStatus/GainMatrixSingle/data/neutral_static/static_NT_bump.csv\")\n",
    "    VI_bump_coord = pd.read_csv(\"/Users/aymericvie/Documents/GitHub/evology/evology/research/TransferStatus/GainMatrixSingle/data/neutral_static/static_VI_bump.csv\")\n",
    "    TF_bump_coord = pd.read_csv(\"/Users/aymericvie/Documents/GitHub/evology/evology/research/TransferStatus/GainMatrixSingle/data/neutral_static/static_TF_bump.csv\")\n",
    "\n",
    "h = 2/128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.07983627474927417 -0.07905126491940513 0.02439804545038659\n",
      "0.07566840602131374 0.07566861278994069 0.03776944577340998\n",
      "0.00951344332179784 0.00951366299541504 0.008081695943202289\n",
      "-1.0456537954333933 -1.0428714999316262 0.008081695943202289\n"
     ]
    }
   ],
   "source": [
    "''' Gain matrix estimation without outliers '''\n",
    "np.set_printoptions(suppress=True)\n",
    "margin = 3\n",
    "\n",
    "# standard_coord = pd.read_csv(\"/Users/aymericvie/Documents/GitHub/evology/evology/research/TransferStatus/GainMatrixSingle/data/static_standard.csv\")\n",
    "\n",
    "clean_standard_coord = pd.DataFrame()\n",
    "\n",
    "# new_standard_coord = pd.DataFrame()\n",
    "# new_standard_coord = standard_coord[np.abs(standard_coord['NT_DayReturns']-standard_coord['NT_DayReturns'].mean()) <= (margin*standard_coord['NT_DayReturns'].std())]\n",
    "# standard_coord_NT_Return = new_standard_coord['NT_DayReturns'].mean()\n",
    "clean_standard_coord['NT_DayReturns'] = 100 * standard_coord['NT_DayReturns']\n",
    "standard_coord_NT_Return = np.nanmean(clean_standard_coord['NT_DayReturns'])\n",
    "\n",
    "# new_standard_coord = pd.DataFrame()\n",
    "# new_standard_coord = standard_coord[np.abs(standard_coord['VI_DayReturns']-standard_coord['VI_DayReturns'].mean()) <= (margin*standard_coord['VI_DayReturns'].std())]\n",
    "# standard_coord_VI_Return = new_standard_coord['VI_DayReturns'].mean()\n",
    "clean_standard_coord['VI_DayReturns'] = 100 * standard_coord['VI_DayReturns']\n",
    "standard_coord_VI_Return = np.nanmean(clean_standard_coord['VI_DayReturns'])\n",
    "\n",
    "# new_standard_coord = pd.DataFrame()\n",
    "# new_standard_coord = standard_coord[np.abs(standard_coord['TF_DayReturns']-standard_coord['TF_DayReturns'].mean()) <= (margin*standard_coord['TF_DayReturns'].std())]\n",
    "# standard_coord_TF_Return = new_standard_coord['TF_DayReturns'].mean()\n",
    "clean_standard_coord['TF_DayReturns'] = 100 * standard_coord['TF_DayReturns']\n",
    "standard_coord_TF_Return = np.nanmean(clean_standard_coord['TF_DayReturns'])\n",
    "\n",
    "print(standard_coord_NT_Return, standard_coord_VI_Return, standard_coord_TF_Return)\n",
    "\n",
    "clean_NT_bump_coord = pd.DataFrame()\n",
    "\n",
    "# new_NT_bump_coord = pd.DataFrame()\n",
    "# new_NT_bump_coord = NT_bump_coord[np.abs(NT_bump_coord['NT_DayReturns']-NT_bump_coord['NT_DayReturns'].mean()) <= (margin*NT_bump_coord['NT_DayReturns'].std())]\n",
    "# NT_bump_NT_Return = new_NT_bump_coord['NT_DayReturns'].mean()\n",
    "clean_NT_bump_coord['NT_DayReturns'] = 100 * NT_bump_coord['NT_DayReturns']\n",
    "NT_bump_NT_Return = np.nanmean(clean_NT_bump_coord['NT_DayReturns'])\n",
    "\n",
    "# new_NT_bump_coord = pd.DataFrame()\n",
    "# new_NT_bump_coord = NT_bump_coord[np.abs(NT_bump_coord['VI_DayReturns']-NT_bump_coord['VI_DayReturns'].mean()) <= (margin*NT_bump_coord['VI_DayReturns'].std())]\n",
    "# NT_bump_VI_Return = new_NT_bump_coord['VI_DayReturns'].mean()\n",
    "clean_NT_bump_coord['VI_DayReturns'] = 100 * NT_bump_coord['VI_DayReturns']\n",
    "NT_bump_VI_Return = np.nanmean(clean_NT_bump_coord['VI_DayReturns'])\n",
    "\n",
    "# new_NT_bump_coord = pd.DataFrame()\n",
    "# new_NT_bump_coord = NT_bump_coord[np.abs(NT_bump_coord['TF_DayReturns']-NT_bump_coord['TF_DayReturns'].mean()) <= (margin*NT_bump_coord['TF_DayReturns'].std())]\n",
    "# NT_bump_TF_Return = new_NT_bump_coord['TF_DayReturns'].mean()\n",
    "clean_NT_bump_coord['TF_DayReturns'] = 100 * NT_bump_coord['TF_DayReturns']\n",
    "NT_bump_TF_Return = np.nanmean(clean_NT_bump_coord['TF_DayReturns'])\n",
    "\n",
    "print(NT_bump_NT_Return, NT_bump_VI_Return, NT_bump_TF_Return)\n",
    "\n",
    "\n",
    "clean_VI_bump_coord = pd.DataFrame()\n",
    "\n",
    "# new_VI_bump_coord = pd.DataFrame()\n",
    "# new_VI_bump_coord = VI_bump_coord[np.abs(VI_bump_coord['NT_DayReturns']-VI_bump_coord['NT_DayReturns'].mean()) <= (margin*VI_bump_coord['NT_DayReturns'].std())]\n",
    "# VI_bump_NT_Return = new_VI_bump_coord['NT_DayReturns'].mean()\n",
    "clean_VI_bump_coord['NT_DayReturns'] = 100 * VI_bump_coord['NT_DayReturns']\n",
    "VI_bump_NT_Return = np.nanmean(clean_VI_bump_coord['NT_DayReturns'])\n",
    "\n",
    "# new_VI_bump_coord = pd.DataFrame()\n",
    "# new_VI_bump_coord = VI_bump_coord[np.abs(VI_bump_coord['VI_DayReturns']-VI_bump_coord['VI_DayReturns'].mean()) <= (margin*VI_bump_coord['VI_DayReturns'].std())]\n",
    "# VI_bump_VI_Return = new_VI_bump_coord['VI_DayReturns'].mean()\n",
    "clean_VI_bump_coord['VI_DayReturns'] = 100 * VI_bump_coord['VI_DayReturns']\n",
    "VI_bump_VI_Return = np.nanmean(clean_VI_bump_coord['VI_DayReturns'])\n",
    "\n",
    "# new_VI_bump_coord = pd.DataFrame()\n",
    "# new_VI_bump_coord = VI_bump_coord[np.abs(VI_bump_coord['TF_DayReturns']-VI_bump_coord['TF_DayReturns'].mean()) <= (margin*VI_bump_coord['TF_DayReturns'].std())]\n",
    "# VI_bump_TF_Return = new_VI_bump_coord['TF_DayReturns'].mean()\n",
    "clean_VI_bump_coord['TF_DayReturns'] = 100 * TF_bump_coord['TF_DayReturns']\n",
    "VI_bump_TF_Return = np.nanmean(clean_VI_bump_coord['TF_DayReturns'])\n",
    "\n",
    "print(VI_bump_NT_Return, VI_bump_VI_Return, VI_bump_TF_Return)\n",
    "\n",
    "\n",
    "clean_TF_bump_coord = pd.DataFrame()\n",
    "# new_TF_bump_coord = pd.DataFrame()\n",
    "# new_TF_bump_coord = TF_bump_coord[np.abs(TF_bump_coord['NT_DayReturns']-TF_bump_coord['NT_DayReturns'].mean()) <= (margin*TF_bump_coord['NT_DayReturns'].std())]\n",
    "# TF_bump_NT_Return = new_TF_bump_coord['NT_DayReturns'].mean()\n",
    "clean_TF_bump_coord['NT_DayReturns'] = 100 * TF_bump_coord['NT_DayReturns']\n",
    "TF_bump_NT_Return = np.nanmean(clean_TF_bump_coord['NT_DayReturns'])\n",
    "\n",
    "\n",
    "# new_TF_bump_coord = pd.DataFrame()\n",
    "# new_TF_bump_coord = TF_bump_coord[np.abs(TF_bump_coord['VI_DayReturns']-TF_bump_coord['VI_DayReturns'].mean()) <= (margin*TF_bump_coord['VI_DayReturns'].std())]\n",
    "# TF_bump_VI_Return = new_TF_bump_coord['VI_DayReturns'].mean()\n",
    "clean_TF_bump_coord['VI_DayReturns'] = 100 * TF_bump_coord['VI_DayReturns']\n",
    "TF_bump_VI_Return = np.nanmean(clean_TF_bump_coord['VI_DayReturns'])\n",
    "\n",
    "# new_TF_bump_coord = pd.DataFrame()\n",
    "# new_TF_bump_coord = TF_bump_coord[np.abs(TF_bump_coord['TF_DayReturns']-np.nanmean(TF_bump_coord['TF_DayReturns'])) <= (margin*TF_bump_coord['TF_DayReturns'].std())]\n",
    "# TF_bump_TF_Return = np.nanmean(new_TF_bump_coord['TF_DayReturns'])\n",
    "clean_TF_bump_coord['TF_DayReturns'] = 100 * TF_bump_coord['TF_DayReturns']\n",
    "TF_bump_TF_Return = np.nanmean(clean_TF_bump_coord['TF_DayReturns'])\n",
    "\n",
    "print(TF_bump_NT_Return, TF_bump_VI_Return, TF_bump_TF_Return)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--NT ROW--\n",
      "                T     dof alternative  p-val         CI95%   cohen-d BF10  \\\n",
      "T-test  125.66459  999789   two-sided    0.0  [9.8, 10.11]  0.125678  inf   \n",
      "\n",
      "        power  \n",
      "T-test    1.0  \n",
      "9.95229956931765\n",
      "               T     dof alternative  p-val         CI95%   cohen-d BF10  \\\n",
      "T-test  75.98428  999789   two-sided    0.0  [5.57, 5.87]  0.075992  inf   \n",
      "\n",
      "        power  \n",
      "T-test    1.0  \n",
      "5.718381956548605\n",
      "                 T     dof alternative  p-val             CI95%   cohen-d  \\\n",
      "T-test -230.977084  999789   two-sided    0.0  [-62.34, -61.29]  0.231001   \n",
      "\n",
      "       BF10  power  \n",
      "T-test  inf    1.0  \n",
      "-61.81232132378361\n",
      "--VI ROW--\n",
      "                T     dof alternative  p-val          CI95%   cohen-d BF10  \\\n",
      "T-test  125.74553  999789   two-sided    0.0  [9.75, 10.06]  0.125759  inf   \n",
      "\n",
      "        power  \n",
      "T-test    1.0  \n",
      "9.902072173398142\n",
      "                T     dof alternative  p-val         CI95%   cohen-d BF10  \\\n",
      "T-test  75.794874  999789   two-sided    0.0  [5.52, 5.81]  0.075803  inf   \n",
      "\n",
      "        power  \n",
      "T-test    1.0  \n",
      "5.668155386548491\n",
      "                 T     dof alternative  p-val             CI95%   cohen-d  \\\n",
      "T-test -231.166685  999789   two-sided    0.0  [-62.21, -61.16]  0.231191   \n",
      "\n",
      "       BF10  power  \n",
      "T-test  inf    1.0  \n",
      "-61.68449504078217\n",
      "--TF ROW--\n",
      "                T     dof alternative          p-val        CI95%   cohen-d  \\\n",
      "T-test  36.432382  999789   two-sided  2.032448e-290  [0.81, 0.9]  0.036436   \n",
      "\n",
      "              BF10  power  \n",
      "T-test  1.214e+285    1.0  \n",
      "0.8557696206734977\n",
      "                T     dof alternative  p-val          CI95%   cohen-d BF10  \\\n",
      "T-test -49.573952  999789   two-sided    0.0  [-1.09, -1.0]  0.049579  inf   \n",
      "\n",
      "        power  \n",
      "T-test    1.0  \n",
      "-1.0442463684597956\n",
      "                T     dof alternative  p-val          CI95%   cohen-d BF10  \\\n",
      "T-test -49.573952  999789   two-sided    0.0  [-1.09, -1.0]  0.049579  inf   \n",
      "\n",
      "        power  \n",
      "T-test    1.0  \n",
      "-1.0442463684597956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pingouin/bayesian.py:146: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  bf10 = 1 / ((1 + t**2 / df)**(-(df + 1) / 2) / integr)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pingouin/bayesian.py:146: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  bf10 = 1 / ((1 + t**2 / df)**(-(df + 1) / 2) / integr)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pingouin/bayesian.py:146: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  bf10 = 1 / ((1 + t**2 / df)**(-(df + 1) / 2) / integr)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pingouin/bayesian.py:146: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  bf10 = 1 / ((1 + t**2 / df)**(-(df + 1) / 2) / integr)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pingouin/bayesian.py:146: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  bf10 = 1 / ((1 + t**2 / df)**(-(df + 1) / 2) / integr)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pingouin/bayesian.py:146: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  bf10 = 1 / ((1 + t**2 / df)**(-(df + 1) / 2) / integr)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pingouin/bayesian.py:146: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  bf10 = 1 / ((1 + t**2 / df)**(-(df + 1) / 2) / integr)\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pingouin/bayesian.py:146: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  bf10 = 1 / ((1 + t**2 / df)**(-(df + 1) / 2) / integr)\n"
     ]
    }
   ],
   "source": [
    "import statsmodels as stats \n",
    "import scipy \n",
    "import pingouin as pg\n",
    "\n",
    "def write_signif(res):\n",
    "    if res['p-val'][0] < 0.01:\n",
    "        # signif = str.maketrans('***')\n",
    "        signif = '^{***}'\n",
    "    elif res['p-val'][0] < 0.05:\n",
    "        # signif = str.maketrans('**')\n",
    "        signif = '^{**}'\n",
    "    elif res['p-val'][0] < 0.1:\n",
    "        # signif = str.maketrans('*')\n",
    "        signif = '^{*}'\n",
    "    else:\n",
    "        signif = ''\n",
    "    return signif\n",
    "\n",
    "''' \n",
    "Null hypothesis: means are equal \n",
    "Alternative hypothesis\" means are different \n",
    "\n",
    "For p-value >= alpha: fail to reject null hypothesis\n",
    "For p-value < alpha: reject H0 and accept HA\n",
    "'''\n",
    "\n",
    "print('--NT ROW--')\n",
    "\n",
    "res = pg.ttest(1/h * (clean_NT_bump_coord['NT_DayReturns'] - clean_standard_coord['NT_DayReturns']), 0, correction=False, confidence=0.95)\n",
    "print(res)\n",
    "signif00 = write_signif(res)\n",
    "ci00 = res['CI95%'][0]\n",
    "print(1/h * (clean_NT_bump_coord['NT_DayReturns'] - clean_standard_coord['NT_DayReturns']).mean())\n",
    "\n",
    "\n",
    "res = pg.ttest(1/h  * (clean_VI_bump_coord['NT_DayReturns'] - clean_standard_coord['NT_DayReturns']), 0, correction=False, confidence=0.95)\n",
    "print(res)\n",
    "signif01 = write_signif(res)\n",
    "ci01 = res['CI95%'][0]\n",
    "print(1/h * (clean_VI_bump_coord['NT_DayReturns'] - clean_standard_coord['NT_DayReturns']).mean())\n",
    "\n",
    "res = pg.ttest(1/h * (clean_TF_bump_coord['NT_DayReturns'] - clean_standard_coord['NT_DayReturns']), 0, correction=False, confidence=0.95)\n",
    "print(res)\n",
    "signif02 = write_signif(res)\n",
    "ci02 = res['CI95%'][0]\n",
    "print(1/h * (clean_TF_bump_coord['NT_DayReturns'] - clean_standard_coord['NT_DayReturns']).mean())\n",
    "\n",
    "print('--VI ROW--')\n",
    "\n",
    "res = pg.ttest(1/h * (clean_NT_bump_coord['VI_DayReturns'] - clean_standard_coord['VI_DayReturns']), 0, correction=False, confidence=0.95)\n",
    "print(res)\n",
    "signif10 = write_signif(res)\n",
    "ci10 = res['CI95%'][0]\n",
    "print(1/h * (clean_NT_bump_coord['VI_DayReturns'] - clean_standard_coord['VI_DayReturns']).mean())\n",
    "\n",
    "\n",
    "res = pg.ttest(1/h  * (clean_VI_bump_coord['VI_DayReturns'] - clean_standard_coord['VI_DayReturns']), 0, correction=False, confidence=0.95)\n",
    "print(res)\n",
    "signif11 = write_signif(res)\n",
    "ci11 = res['CI95%'][0]\n",
    "print(1/h * (clean_VI_bump_coord['VI_DayReturns'] - clean_standard_coord['VI_DayReturns']).mean())\n",
    "\n",
    "res = pg.ttest(1/h * (clean_TF_bump_coord['VI_DayReturns'] - clean_standard_coord['VI_DayReturns']), 0, correction=False, confidence=0.95)\n",
    "print(res)\n",
    "signif12 = write_signif(res)\n",
    "ci12 = res['CI95%'][0]\n",
    "print(1/h * (clean_TF_bump_coord['VI_DayReturns'] - clean_standard_coord['VI_DayReturns']).mean())\n",
    "\n",
    "print('--TF ROW--')\n",
    "\n",
    "res = pg.ttest(1/h * (clean_NT_bump_coord['TF_DayReturns'] - clean_standard_coord['TF_DayReturns']), 0, correction=False, confidence=0.95)\n",
    "print(res)\n",
    "signif20 = write_signif(res)\n",
    "ci20 = res['CI95%'][0]\n",
    "print(1/h * (clean_NT_bump_coord['TF_DayReturns'] - clean_standard_coord['TF_DayReturns']).mean())\n",
    "\n",
    "\n",
    "res = pg.ttest(1/h  * (clean_VI_bump_coord['TF_DayReturns'] - clean_standard_coord['TF_DayReturns']), 0, correction=False, confidence=0.95)\n",
    "print(res)\n",
    "signif21 = write_signif(res)\n",
    "ci21 = res['CI95%'][0]\n",
    "print(1/h * (clean_VI_bump_coord['TF_DayReturns'] - clean_standard_coord['TF_DayReturns']).mean())\n",
    "\n",
    "res = pg.ttest(1/h * (clean_TF_bump_coord['TF_DayReturns'] - clean_standard_coord['TF_DayReturns']), 0, correction=False, confidence=0.95)\n",
    "print(res)\n",
    "signif22 = write_signif(res)\n",
    "ci22 = res['CI95%'][0]\n",
    "print(1/h * (clean_TF_bump_coord['TF_DayReturns'] - clean_standard_coord['TF_DayReturns']).mean())\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "GainMatrix = np.zeros((3,3))\n",
    "h = 2/256\n",
    "h = 2/128\n",
    "\n",
    "''' It is mutliplied by 1/h by finite difference, and by 100 to obtain percentages '''\n",
    "\n",
    "GainMatrix[0,0] = round(100/h * (NT_bump_NT_Return - standard_coord_NT_Return),3)\n",
    "GainMatrix[0,1] = round(100/h * (VI_bump_NT_Return - standard_coord_NT_Return),3)\n",
    "GainMatrix[0,2] = round(100/h * (TF_bump_NT_Return - standard_coord_NT_Return),3)\n",
    "\n",
    "GainMatrix[1,0] = round(100/h * (NT_bump_VI_Return - standard_coord_VI_Return),3)\n",
    "GainMatrix[1,1] = round(100/h * (VI_bump_VI_Return - standard_coord_VI_Return),3)\n",
    "GainMatrix[1,2] = round(100/h * (TF_bump_VI_Return - standard_coord_VI_Return),3)\n",
    "\n",
    "GainMatrix[2,0] = round(100/h * (NT_bump_TF_Return - standard_coord_TF_Return),3)\n",
    "GainMatrix[2,1] = round(100/h * (VI_bump_TF_Return - standard_coord_TF_Return),3)\n",
    "GainMatrix[2,2] = round(100/h * (TF_bump_TF_Return - standard_coord_TF_Return),3)\n",
    "\n",
    "# print(GainMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Texttable Table:\n",
      "+----+----------------+----------------+------------------+\n",
      "|    |       NT       |       VI       |        TF        |\n",
      "+====+================+================+==================+\n",
      "| NT | 1990.46^{***}  | 1143.676^{***} | -12362.464^{***} |\n",
      "| VI | 1980.414^{***} | 1133.631^{***} | -12336.899^{***} |\n",
      "| TF | 171.154^{***}  | -208.849^{***} | -208.849^{***}   |\n",
      "+----+----------------+----------------+------------------+\n",
      "\\begin{table}\n",
      "\t\\begin{center}\n",
      "\t\t\\begin{tabular}{|C|C|C|C|}\n",
      "\t\t\t\\hline\n",
      "\t\t\t & NT & VI & TF \\\\\n",
      "\t\t\t\\hline\n",
      "\t\t\tNT & 1990.46^{***} & 1143.676^{***} & -12362.464^{***} \\\\\n",
      "\t\t\tVI & 1980.414^{***} & 1133.631^{***} & -12336.899^{***} \\\\\n",
      "\t\t\tTF & 171.154^{***} & -208.849^{***} & -208.849^{***} \\\\\n",
      "\t\t\t\\hline\n",
      "\t\t\\end{tabular}\n",
      "\t\\end{center}\n",
      "\t\\caption{Gain matrix at the equal wealth coordinates. Significance is showed for p-value inferior to 0.01 (***), 0.05 (**) and 0.1 (*).}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "from texttable import Texttable\n",
    "import latextable\n",
    "\n",
    "rows = [['', 'NT', 'VI', 'TF'],\n",
    "        ['NT', str(GainMatrix[0,0]) + str(signif00), str(GainMatrix[0,1]) + str(signif01), str(GainMatrix[0,2]) + str(signif02)],\n",
    "        ['VI', str(GainMatrix[1,0]) + str(signif10), str(GainMatrix[1,1]) + str(signif11), str(GainMatrix[1,2]) + str(signif12)],\n",
    "        ['TF', str(GainMatrix[2,0]) + str(signif20), str(GainMatrix[2,1]) + str(signif21), str(GainMatrix[2,2]) + str(signif22)]]\n",
    "\n",
    "table = Texttable()\n",
    "table.set_cols_align([\"C\"] * 4)\n",
    "table.set_deco(Texttable.HEADER | Texttable.VLINES | Texttable.BORDER)\n",
    "table.add_rows(rows)\n",
    "\n",
    "\n",
    "print('\\nTexttable Table:')\n",
    "print(table.draw())\n",
    "print(latextable.draw_latex(table, \n",
    "        caption=\"Gain matrix at the equal wealth coordinates. Significance is showed for p-value inferior to 0.01 (***), 0.05 (**) and 0.1 (*).\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Texttable Table:\n",
      "+----+---------------+---------------+-----------------+\n",
      "|    |      NT       |      VI       |       TF        |\n",
      "+====+===============+===============+=================+\n",
      "| NT | [ 9.8  10.11] | [5.57 5.87]   | [-62.34 -61.29] |\n",
      "| VI | [ 9.75 10.06] | [5.52 5.81]   | [-62.21 -61.16] |\n",
      "| TF | [0.81 0.9 ]   | [-1.09 -1.  ] | [-1.09 -1.  ]   |\n",
      "+----+---------------+---------------+-----------------+\n",
      "\\begin{table}\n",
      "\t\\begin{center}\n",
      "\t\t\\begin{tabular}{|C|C|C|C|}\n",
      "\t\t\t\\hline\n",
      "\t\t\t & NT & VI & TF \\\\\n",
      "\t\t\t\\hline\n",
      "\t\t\tNT & [ 9.8  10.11] & [5.57 5.87] & [-62.34 -61.29] \\\\\n",
      "\t\t\tVI & [ 9.75 10.06] & [5.52 5.81] & [-62.21 -61.16] \\\\\n",
      "\t\t\tTF & [0.81 0.9 ] & [-1.09 -1.  ] & [-1.09 -1.  ] \\\\\n",
      "\t\t\t\\hline\n",
      "\t\t\\end{tabular}\n",
      "\t\\end{center}\n",
      "\t\\caption{95\\% Confidence intervals of the gain matrix entries at the equal wealth coordinates}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "from texttable import Texttable\n",
    "import latextable\n",
    "\n",
    "rows = [['', 'NT', 'VI', 'TF'],\n",
    "        ['NT', str(ci00), str(ci01), str(ci02)],\n",
    "        ['VI', str(ci10), str(ci11), str(ci12)],\n",
    "        ['TF', str(ci20), str(ci21), str(ci22)]]\n",
    "\n",
    "table = Texttable()\n",
    "table.set_cols_align([\"C\"] * 4)\n",
    "table.set_deco(Texttable.HEADER | Texttable.VLINES | Texttable.BORDER)\n",
    "table.add_rows(rows)\n",
    "\n",
    "\n",
    "print('\\nTexttable Table:')\n",
    "print(table.draw())\n",
    "print(latextable.draw_latex(table, caption=\"95\\% Confidence intervals of the gain matrix entries at the equal wealth coordinates\"))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
